{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import subprocess,os\n",
    "# result = subprocess.run( ['mkdir','da'], stdout=subprocess.PIPE )\n",
    "# print(result.stdout.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\ddwell\\\\Documents\\\\Ecology\\\\data\\\\untitled.txt']"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd = 'C:\\\\Users\\\\ddwell\\\\Documents\\\\Ecology'\n",
    "\n",
    "def _get_input_files(directory, extensions=['.csv']):    \n",
    "    files_list = []    \n",
    "    filenames_array = [filenames for root, dirnames, filenames in os.walk(directory)]\n",
    "    files  = [val for sublist in filenames_array for val in sublist]    \n",
    "    \n",
    "    if len(extensions) <= 1:\n",
    "        files_list = [os.path.join(directory,file) for file in files if file.endswith(extensions[0])]\n",
    "    else:\n",
    "        for file in files:\n",
    "            for ext in extensions:\n",
    "                if file.endswith(ext):\n",
    "                    files_list.append(os.path.join(directory,file))\n",
    "    return files_list\n",
    "                \n",
    "\n",
    "files = _get_input_files(os.path.join(pwd,'data'), extensions=['.txt'])\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from decimal import Decimal \n",
    "import numpy as np\n",
    "import time,datetime\n",
    "import dateutil.parser as dparser\n",
    "from collections import Counter\n",
    "\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup as BS\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_chromedriver = 'C:\\Games\\chromedriver\\chromedriver.exe' # change path as needed\n",
    "browser = webdriver.Chrome(executable_path = path_to_chromedriver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pageURL = 'http://ceb-uk.kz/map/'\n",
    "browser.get(pageURL)\n",
    "browser.find_element_by_class_name('toggle-menu').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_posts_info(content):\n",
    "    posts_data = {}\n",
    "\n",
    "    for post in content.find_all(\"div\",{'class':'clear item'}):\n",
    "        \n",
    "        post_name = post.find('b').contents[0]\n",
    "        post_id = re.findall(r'\\d+', post_name)[0]\n",
    "        \n",
    "        post_info =  {post_id:{ \n",
    "            'post_name':post_name,\n",
    "            'post_description':post.find(\"div\",{'class':'lite'}).contents[0], \n",
    "            'post_address':post.find(\"div\",{'class':'lite'}).contents[2].text}}\n",
    "\n",
    "        posts_data.update(post_info)\n",
    "        \n",
    "    return posts_data\n",
    "\n",
    "content = BS(browser.page_source, 'lxml')  \n",
    "posts_data = get_posts_info(content)\n",
    "\n",
    "with open('data/posts.json', 'w') as csvfile:\n",
    "    csvfile.write(str(posts_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "content = BS(browser.page_source, 'lxml') \n",
    "text = content.find(\"span\",{'id':'date'}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2018-10-01 18:33:00'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp = dparser.parse(text, fuzzy=True).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_post_measurements(content):\n",
    "    \n",
    "    popup = content.find(\"div\",{'class':'leaflet-popup-content-wrapper'})\n",
    "    post_name = popup.find(\"div\",{'class':'popup'}).find('b').contents[0]\n",
    "    post_id = re.findall(r'\\d+', post_name)[0]\n",
    "\n",
    "    post_measurements = {}\n",
    "\n",
    "    for row in popup.find(\"div\",{'class':'leaflet-popup-content'}).find_all(\"div\",{'class':'indicators'}):\n",
    "        for indicator in row.find_all(\"div\",{'class':'clear'}):\n",
    "            if indicator is not None:\n",
    "                param = indicator.find('b').text[:-1]\n",
    "                measurement = indicator.contents[3][:-4].strip()\n",
    "                post_measurements.update({param : measurement})\n",
    "\n",
    "    return post_id,post_measurements\n",
    "\n",
    "data_header, data_entry = [], []\n",
    "\n",
    "for i,element in enumerate(browser.find_elements_by_class_name('clear')):\n",
    "    element.click()\n",
    "    content = BS(browser.page_source, 'lxml') \n",
    "    \n",
    "    post_id, post_measurements = get_post_measurements(content)\n",
    "    \n",
    "    data_header.append( ','.join([post_id+'_'+x for x in post_measurements.keys()]) )\n",
    "    data_entry.append( ','.join(post_measurements.values()) ) \n",
    "    \n",
    "    delay = np.random.randint(3) + np.random.rand()\n",
    "    time.sleep(delay)\n",
    "    \n",
    "    if i>=8:\n",
    "        break  \n",
    "\n",
    "print('timestamp,' + ',\\t'.join(data_header))\n",
    "print(str(timestamp)+','+ ',\\t'.join(data_entry))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# browser.find_element_by_class_name('toggle-menu').click()\n",
    "browser.find_elements_by_tag_name('option')[-1].click()# class_name('switcher').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "content = BS(browser.page_source, 'lxml') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from decimal import Decimal \n",
    "import numpy as np\n",
    "import time, datetime\n",
    "import dateutil.parser as dparser\n",
    "from collections import Counter\n",
    "\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup as BS\n",
    "from selenium import webdriver\n",
    "\n",
    "def get_post_measurements(content):    \n",
    "    popup = content.find(\"div\",{'class':'leaflet-popup-content-wrapper'})\n",
    "    post_name = popup.find(\"div\",{'class':'popup'}).find('b').contents[0]\n",
    "    post_id = re.findall(r'\\d+', post_name)[0]\n",
    "    post_measurements = {}\n",
    "    for row in popup.find(\"div\",{'class':'leaflet-popup-content'}).find_all(\"div\",{'class':'indicators'}):\n",
    "        for indicator in row.find_all(\"div\",{'class':'clear'}):\n",
    "            if indicator is not None:\n",
    "                param = indicator.find('b').text[:-1]\n",
    "                measurement = indicator.contents[3][:-4].strip()\n",
    "                if 'обслуж' in measurement:\n",
    "                    measurement = '-1'\n",
    "                post_measurements.update({param : measurement})\n",
    "    return post_id,post_measurements\n",
    "\n",
    "def get_weather_measurements(content):    \n",
    "    weather_data = []\n",
    "    for post in content.find(\"div\",{'id':'data'}).find_all(\"div\",{'class':'popup'}):\n",
    "        if not 'обслуж' in post.text:\n",
    "            wind = post.find('span').attrs['title']\n",
    "            extData = [i.text for i in post.find_all(\"strong\")]\n",
    "            extData.append(re.search('(?<=\\().*?(?=\\))', wind).group()[:-1])\n",
    "            weather_data += extData[1:]\n",
    "        else:\n",
    "            weather_data += ['-1']*6\n",
    "    return weather_data\n",
    "\n",
    "def getMeasurementsNow(browser, spf = 1200.0, period = 60*60*24,pageURL = 'http://ceb-uk.kz/map/'):    \n",
    "        \n",
    "    outfilename = os.path.join(os.path.abspath('data'),time.strftime('%Y-%m-%d', time.localtime(time.time())) + '.csv')\n",
    "    \n",
    "    if not os.path.exists(outfilename):\n",
    "        mode = 'w+'\n",
    "    elif os.stat(outfilename).st_size > 0:\n",
    "        mode = 'a'        \n",
    "    else:\n",
    "        mode = 'w'\n",
    "        \n",
    "    with open(outfilename, mode) as csvfile:\n",
    "        print(\"<%s>\" % outfilename)         \n",
    "        if mode == 'w+' or mode =='w':\n",
    "            csvfile.write('servertime,timestamp,1_CO,1_CxHy,1_HCl,1_HCOH,1_NO2,1_SO2,2_CO,2_CxHy,2_HCl,2_HCOH,2_NO2,2_SO2,3_CO,3_CxHy,3_HCl,3_HCOH,3_NO2,3_SO2,4_CO,4_CxHy,4_HCl,4_HCOH,4_NO2,4_SO2,5_CO,5_CxHy,5_HCl,5_HCOH,5_NO2,5_SO2,6_CO,6_CxHy,6_HCl,6_HCOH,6_NO2,6_SO2,7_CO,7_CxHy,7_HCl,7_HCOH,7_NO2,7_SO2,8_Cl2,8_CO,8_CxHy,8_HCOH,8_NO2,8_SO2,9_CO,9_CxHy,9_HCOH,9_HF,9_NO2,9_SO2,11_temp, 11_atmp, 11_windspeed, 11_humi, 11_precipitation, 11_winddirection, 12_temp, 12_atmp, 12_windspeed, 12_humi, 12_precipitation, 12_winddirection')\n",
    "            csvfile.write('\\n')     \n",
    "\n",
    "    try:\n",
    "        browser.get(pageURL)\n",
    "        \n",
    "        delay = 1 + np.random.randint(2) + np.random.rand()\n",
    "        time.sleep(delay)\n",
    "        \n",
    "        browser.find_element_by_class_name('toggle-menu').click()\n",
    "\n",
    "        delay = 1 + np.random.randint(2) + np.random.rand()\n",
    "        time.sleep(delay)\n",
    "                \n",
    "        content = BS(browser.page_source, 'lxml') \n",
    "\n",
    "        data_entry = []\n",
    "        for i,element in enumerate(browser.find_elements_by_class_name('clear')):\n",
    "            element.click()\n",
    "            content = BS(browser.page_source, 'lxml') \n",
    "\n",
    "            post_id, post_measurements = get_post_measurements(content)\n",
    "            data_entry.append( ','.join(post_measurements.values()) ) \n",
    "\n",
    "            delay = np.random.randint(2) + np.random.rand()\n",
    "            time.sleep(delay)\n",
    "            if i>=8:\n",
    "                break \n",
    "\n",
    "        browser.find_elements_by_tag_name('option')[-1].click()\n",
    "        content = BS(browser.page_source, 'lxml') \n",
    "        data_entry_weather = get_weather_measurements(content)                \n",
    "\n",
    "        content = BS(browser.page_source, 'lxml') \n",
    "        text = content.find(\"span\",{'id':'date'}).text\n",
    "\n",
    "        servertime = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time()))\n",
    "        timestamp = dparser.parse(text, fuzzy=True).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        line = servertime+','+timestamp+',' +','.join(data_entry+data_entry_weather)\n",
    "\n",
    "        with open(outfilename, 'a') as csvfile:\n",
    "            csvfile.write(line)\n",
    "            csvfile.write('\\n')\n",
    "            \n",
    "        print(\"%s, %s\" % (servertime, timestamp)  )\n",
    "        \n",
    "        browser.find_element_by_class_name('toggle-menu').click()\n",
    "\n",
    "        delay = 1 + np.random.randint(10) + np.random.rand()\n",
    "\n",
    "    except:\n",
    "        print(\"\\nprocess interrupted %s\" % time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time()))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<C:\\Users\\ddwell\\Documents\\Ecology\\data\\2018-01-10.csv> open\n",
      "2018-01-10 19:20:40, 2018-11-01 01:13:00\n"
     ]
    }
   ],
   "source": [
    "path_to_chromedriver = os.path.join(os.path.abspath('chromedriver'), 'chromedriver.exe') \n",
    "browser = webdriver.Chrome(executable_path = path_to_chromedriver)\n",
    "\n",
    "pageURL = 'http://ceb-uk.kz/map/'\n",
    "#browser.get(pageURL)\n",
    "#browser.find_element_by_class_name('toggle-menu').click()\n",
    "\n",
    "# try:\n",
    "getMeasurementsNow(pageURL = pageURL)\n",
    "# except:\n",
    "browser.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<C:\\Users\\ddwell\\Documents\\Ecology\\data\\2018-01-10.csv>\n",
      "2018-01-10 19:32:47, 2018-11-01 01:13:00\n",
      "<C:\\Users\\ddwell\\Documents\\Ecology\\data\\2018-01-10.csv>\n",
      "2018-01-10 19:53:32, 2018-11-01 01:33:00\n"
     ]
    }
   ],
   "source": [
    "path_to_chromedriver = os.path.join(os.path.abspath('chromedriver'), 'chromedriver.exe') \n",
    "\n",
    "try:\n",
    "    spf = 1200\n",
    "    frametime = spf  \n",
    "    starttime = 0\n",
    "    while True:                  \n",
    "        if frametime >= spf:        \n",
    "            starttime = time.time() \n",
    "            \n",
    "            browser = webdriver.Chrome(executable_path = path_to_chromedriver)\n",
    "            \n",
    "            getMeasurementsNow(pageURL = pageURL, browser = browser)\n",
    "            \n",
    "            browser.close()\n",
    "            #servertime = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time()))\n",
    "            #print(servertime)\n",
    "\n",
    "        #FIXED TIME STEP technique\n",
    "        frametime = time.time() - starttime \n",
    "except(KeyboardInterrupt, SystemExit):    \n",
    "    servertime = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time()))\n",
    "    print('%s process interrupted' % servertime)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
